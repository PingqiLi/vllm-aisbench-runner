# Qwen3-30B-A3B - Performance Testing
# Optimized for throughput benchmarking

model:
  name: "Qwen3-30B-A3B"
  precision: "bf16"
  description: "Performance testing configuration"

vllm:
  model_path: "Qwen/Qwen3-30B-A3B"
  host: "localhost"
  port: 8000
  tensor_parallel_size: 2
  dtype: "bfloat16"
  gpu_memory_utilization: 0.90
  trust_remote_code: true
  max_num_seqs: 256
  enable_prefix_caching: true
  max_model_len: 32768
  timeout: 600
  log_file: "logs/qwen3_30b_perf_vllm.log"

aisbench:
  model: "vllm_api_stream_chat"   # Use streaming for perf tests
  mode: "perf"
  max_num_workers: 8

# Hardware requirements
hardware:
  min_gpus: 2
  memory_per_gpu: "60GB"
